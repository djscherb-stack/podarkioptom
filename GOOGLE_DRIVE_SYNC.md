# Автозагрузка отчётов из Google Drive

Сайт может автоматически забирать новые Excel-файлы из **одной папки** Google Drive и загружать их в аналитику. Поддерживаются два типа файлов:

- имя начинается с **«Выпуск продукции»** — выпуск продукции по подразделениям;
- имя начинается с **«Выработка сотрудников»** — выработка сотрудников по операциям сканирования.

---

## Шаг 1. Проект в Google Cloud

1. Откройте [Google Cloud Console](https://console.cloud.google.com/).
2. Создайте новый проект или выберите существующий.
3. В меню слева: **APIs & Services** → **Library**.
4. Найдите **Google Drive API** и нажмите **Enable** (Включить).

---

## Шаг 2. Service Account (сервисный аккаунт)

1. **APIs & Services** → **Credentials** → **Create Credentials** → **Service Account**.
2. Имя: например `analytics-sync`.
3. Нажмите **Create and Continue**.
4. Роль можно не назначать → **Done**.
5. Откройте созданный сервисный аккаунт (клик по email).
6. Вкладка **Keys** → **Add Key** → **Create new key** → **JSON** → **Create**.
7. Сохраните скачанный JSON-файл — он понадобится на шаге 5.

**Важно:** Скопируйте **email сервисного аккаунта** (типа `analytics-sync@project-id.iam.gserviceaccount.com`) — он нужен для шага 4.

---

## Шаг 3. Папка в Google Drive

1. Создайте папку в Google Drive для отчётов (или используйте существующую).
2. Убедитесь, что 1С настроена на выгрузку в эту папку.
3. Откройте папку в браузере и скопируйте ID из URL:
   ```
   https://drive.google.com/drive/folders/1ABCdefGHIjkLMnoPQRstuVWXyz
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                                        это Folder ID
   ```

---

## Шаг 4. Доступ к папке для Service Account

1. Правый клик по папке в Google Drive → **Share** (Настройки доступа).
2. Добавьте **email сервисного аккаунта** (из шага 2) с правами **Viewer** (Читатель).
3. Нажмите **Share** / **Готово**.

Без этого шага сайт не сможет читать файлы в папке.

---

## Шаг 5. Переменные окружения на Render

В [Render Dashboard](https://dashboard.render.com/) → ваш сервис → **Environment** → **Environment Variables** добавьте:

| Переменная | Значение |
|------------|----------|
| `GOOGLE_DRIVE_FOLDER_ID` | ID папки из шага 3 |
| `GOOGLE_DRIVE_CREDENTIALS_JSON` | **Всё содержимое** JSON-файла из шага 2 (одной строкой) |
| `UPLOAD_TOKEN` | Секретный токен для вызова sync (если ещё не задан) |

### Как вставить JSON в Render

1. Откройте скачанный JSON в текстовом редакторе.
2. Скопируйте **весь текст** (от `{` до `}`).
3. В Render: **Add Environment Variable** → Key: `GOOGLE_DRIVE_CREDENTIALS_JSON`.
4. Value: вставьте скопированный JSON.
5. **Важно:** JSON должен быть одной строкой. Если Render ругается, можно использовать [jsonformatter.org](https://jsonformatter.org/json-minify) чтобы убрать переносы.

### Опционально

| Переменная | По умолчанию | Описание |
|------------|--------------|----------|
| `GOOGLE_DRIVE_PREFIX_PRODUCTION` | `Выпуск продукции` | Начало имени файла для выпуска продукции |
| `GOOGLE_DRIVE_PREFIX_EMPLOYEE_OUTPUT` | `Выработка сотрудников` | Начало имени файла для выработки сотрудников (из той же папки) |
| `GOOGLE_DRIVE_RECURSIVE` | `true` | Искать файлы и в подпапках (`true` / `false`) |

---

## Шаг 6. Автосинхронизация в 8–10 утра по Москве

Москва = UTC+3. Чтобы синхронизация запускалась каждый день в 8:00 по Москве:
- 8:00 МСК = 5:00 UTC → cron: `0 5 * * *`
- 9:00 МСК = 6:00 UTC → cron: `0 6 * * *`
- 10:00 МСК = 7:00 UTC → cron: `0 7 * * *`

### Вариант A: Render Cron Job (если доступен)

1. **Dashboard** → **New** → **Cron Job**.
2. Name: `analytics-gdrive-sync`.
3. **Command:**
   ```bash
   curl -s -H "X-Upload-Token: ВАШ_UPLOAD_TOKEN" https://podarkioptom.onrender.com/api/sync-from-gdrive
   ```
4. **Schedule:** `0 5 * * *` (ежедневно в 8:00 по Москве).
5. **Region:** тот же, что у веб-сервиса.
6. **Create Cron Job**.

### Вариант B: cron-job.org (бесплатно, подходит для Free-тарифа)

1. Зарегистрируйтесь на [cron-job.org](https://cron-job.org).
2. **Create Cronjob**:
   - **Title:** Синхронизация аналитики
   - **URL:** `https://podarkioptom.onrender.com/api/sync-from-gdrive`
   - **Request method:** GET
   - **Request headers:** `X-Upload-Token: ВАШ_UPLOAD_TOKEN`
3. **Schedule** → выберите **Daily** → 08:00, Timezone: **Europe/Moscow**.
4. Сохраните.

### Вариант C: Три раза (8:00, 9:00, 10:00 МСК)

В cron-job.org создайте три задания на 08:00, 09:00 и 10:00 (Europe/Moscow).

### Важно: холодный старт Render Free

На **Free-тарифе** Render останавливает сервис после ~15 минут неактивности. Первый запрос «будит» его, это занимает **30–60 секунд**. cron-job.org обычно даёт таймаут 30 сек — запрос может оборваться до того, как сервер ответит.

**Решение:** создайте второе задание в cron-job.org — «прогрев» за 2–3 минуты до синхронизации:
- **Title:** Прогрев сервера
- **URL:** `https://podarkioptom.onrender.com/` (главная страница)
- **Schedule:** Daily 07:57 (Europe/Moscow)

Так сервер успеет проснуться, и в 08:00 синхронизация пройдёт.

### Лог синхронизации в админке

В **Админ** → **Лог синхронизации** отображаются последние запуски (по расписанию и вручную): время, источник (cron/админка), результат, загруженные файлы, ошибки. По нему можно понять, дошёл ли запрос от cron до сервера.

---

## Шаг 7. Ручная проверка

Проверьте синхронизацию вручную (замените токен и URL):

```bash
curl -H "X-Upload-Token: ВАШ_UPLOAD_TOKEN" https://podarkioptom.onrender.com/api/sync-from-gdrive
```

**Успешный ответ (могут быть оба типа файлов):**
```json
{
  "ok": true,
  "downloaded": [
    {"name": "Выпуск продукции 01.02.2026.xlsx", "saved_as": "gdrive_20260201_120000_abc12345.xlsx"},
    {"name": "Выработка сотрудников 5 февраля.xlsx", "saved_as": "gdrive_20260201_120001_def67890.xlsx"}
  ],
  "errors": []
}
```

**Если новых файлов нет:**
```json
{"ok": true, "downloaded": [], "errors": []}
```

---

## Как это устроено

1. По расписанию (cron) или вручную вызывается `/api/sync-from-gdrive`.
2. Сайт подключается к Google Drive по Service Account.
3. Сканирует папку (и подпапки) и ищет файлы `.xlsx` / `.xls`, имя которых начинается с **«Выпуск продукции»** или **«Выработка сотрудников»**.
4. Файлы, которые уже были загружены ранее, пропускаются (учёт по `file_id`).
5. Новые файлы скачиваются и сохраняются в `data/`.
6. Данные обновляются (продукция и выработка), после чего отражаются в аналитике и на странице «Выработка сотрудников».
